{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e432085-2ff6-4816-84b0-151ece1a75ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark Session gi√† attiva\n",
      "Spark Version: 3.5.7\n",
      "App Name: Valmet-Notebook\n",
      "Master: spark://spark-master:7077\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, max, min, coalesce\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "import json\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Valmet-Notebook\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark Session gi√† attiva\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"App Name: {spark.sparkContext.appName}\")\n",
    "print(f\"Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84a6909-026b-4b31-b652-f45a3ec210e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    SparkFiles.get(\"/opt/spark/data/20251204_bronze.csv\"),\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb86580-bef5-435d-9f61-e307f9178c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+-----------+---------------------+-----------+--------------------+--------------------+------------+-------------+-------------------+-------------------+----------+\n",
      "|ArrayIndex_metrics|custumerID|messageToID|EventProcessedUtcTime|PartitionId|EventEnqueuedUtcTime|                name|       value|    timestamp|     timestamp_true|formatted_timestamp| date_only|\n",
      "+------------------+----------+-----------+---------------------+-----------+--------------------+--------------------+------------+-------------+-------------------+-------------------+----------+\n",
      "|                 0|  10048224|    2717272| 2025-12-04 07:50:...|          1|2025-12-04 07:50:...|CONV.LS1.Status.P...|        91.8|1764834618282|2025-12-04 07:50:18|2025-12-04 07:50:18|2025-12-04|\n",
      "|                 2|  10048224|    2717272| 2025-12-04 07:50:...|          1|2025-12-04 07:50:...|CONV.LS1.Status.P...|       117.0|1764834618282|2025-12-04 07:50:18|2025-12-04 07:50:18|2025-12-04|\n",
      "|                 3|  10048224|    2717272| 2025-12-04 07:50:...|          1|2025-12-04 07:50:...|CONV.LS1.Status.P...|      2680.0|1764834618282|2025-12-04 07:50:18|2025-12-04 07:50:18|2025-12-04|\n",
      "|                 4|  10048224|    2717272| 2025-12-04 07:50:...|          1|2025-12-04 07:50:...|CONV.LS1.Statisti...|        52.0|1764834618282|2025-12-04 07:50:18|2025-12-04 07:50:18|2025-12-04|\n",
      "|                12|  10048224|    2717272| 2025-12-04 07:50:...|          1|2025-12-04 07:50:...|CONV.LS1.Statisti...|4.15744559E8|1764834618282|2025-12-04 07:50:18|2025-12-04 07:50:18|2025-12-04|\n",
      "+------------------+----------+-----------+---------------------+-----------+--------------------+--------------------+------------+-------------+-------------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- ArrayIndex_metrics: integer (nullable = true)\n",
      " |-- custumerID: integer (nullable = true)\n",
      " |-- messageToID: integer (nullable = true)\n",
      " |-- EventProcessedUtcTime: timestamp (nullable = true)\n",
      " |-- PartitionId: integer (nullable = true)\n",
      " |-- EventEnqueuedUtcTime: timestamp (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- timestamp_true: timestamp (nullable = true)\n",
      " |-- formatted_timestamp: timestamp (nullable = true)\n",
      " |-- date_only: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78572e5d-7106-43eb-9998-22105ff56fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"/opt/spark/data/metrics_name_mapping_dict.json\"\n",
    "with open(json_path, 'r') as f:\n",
    "    mapping_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3f7c35-1d15-457e-80b5-898f705abf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabella di Mapping Corretta (Esempio):\n",
      "+----------------------------------------------------+----------------------------------------------------+\n",
      "|raw_name_map                                        |normalized_name_map                                 |\n",
      "+----------------------------------------------------+----------------------------------------------------+\n",
      "|CONV.LINE.Status.Monitoring.Process.Speed           |CONV.LINE.Status.Monitoring.Process.Speed           |\n",
      "|CONV.LINE.Status.Speed                              |CONV.LINE.Status.Monitoring.Process.Speed           |\n",
      "|CONV.LINE.Status.State.Speed                        |CONV.LINE.Status.Monitoring.Process.Speed           |\n",
      "|CONV.LINE.Statistics.Production.Log.ProducedNotReset|CONV.LINE.Statistics.Production.Log.ProducedNotReset|\n",
      "|CONV.REW.Statistics.Production.LogProduced.NotReset |CONV.LINE.Statistics.Production.Log.ProducedNotReset|\n",
      "+----------------------------------------------------+----------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Dataset Normalizzato Correttamente:\n",
      "+------------------+----------+-----------+-----------------------+-----------+-----------------------+----------------------------------------------------+-----------+-------------+-------------------+-------------------+----------+\n",
      "|ArrayIndex_metrics|custumerID|messageToID|EventProcessedUtcTime  |PartitionId|EventEnqueuedUtcTime   |name                                                |value      |timestamp    |timestamp_true     |formatted_timestamp|date_only |\n",
      "+------------------+----------+-----------+-----------------------+-----------+-----------------------+----------------------------------------------------+-----------+-------------+-------------------+-------------------+----------+\n",
      "|61                |10048224  |2717272    |2025-12-04 07:50:24.574|1          |2025-12-04 07:50:24.48 |CONV.ACC1.Statistics.Production.Log.PercentageLevel |12.0       |1764834619773|2025-12-04 07:50:19|2025-12-04 07:50:19|2025-12-04|\n",
      "|19                |10039685  |2593266    |2025-12-04 01:46:22.746|0          |2025-12-04 01:46:22.519|CONV.ACC1.Statistics.Production.Log.PercentageLevel |86.0       |1764812781674|2025-12-04 01:46:21|2025-12-04 01:46:21|2025-12-04|\n",
      "|19                |10039685  |2613924    |2025-12-04 02:51:16.172|2          |2025-12-04 02:51:16.075|CONV.ACC1.Statistics.Production.Log.PercentageLevel |68.0       |1764816675860|2025-12-04 02:51:15|2025-12-04 02:51:15|2025-12-04|\n",
      "|5                 |10039685  |2664855    |2025-12-04 05:24:44.468|2          |2025-12-04 05:24:44.315|CONV.LINE.Statistics.Production.Log.ProducedNotReset|8461955.0  |1764825881307|2025-12-04 05:24:41|2025-12-04 05:24:41|2025-12-04|\n",
      "|56                |10052103  |2815887    |2025-12-04 12:19:06.295|2          |2025-12-04 12:19:06.015|CONV.LINE.Statistics.Production.Log.ProducedNotReset|1.1538972E7|1764850743008|2025-12-04 12:19:03|2025-12-04 12:19:03|2025-12-04|\n",
      "|68                |10048224  |2703961    |2025-12-04 07:14:02.557|1          |2025-12-04 07:14:02.397|CONV.LINE.Statistics.Production.Log.RejectedNotReset|358329.0   |1764832438433|2025-12-04 07:13:58|2025-12-04 07:13:58|2025-12-04|\n",
      "|4                 |10039685  |2664855    |2025-12-04 05:24:44.468|2          |2025-12-04 05:24:44.315|CONV.LINE.Statistics.Production.Log.RejectedNotReset|41620.0    |1764825881307|2025-12-04 05:24:41|2025-12-04 05:24:41|2025-12-04|\n",
      "|57                |10052103  |2815887    |2025-12-04 12:19:06.295|2          |2025-12-04 12:19:06.015|CONV.LINE.Statistics.Production.Log.RejectedNotReset|113096.0   |1764850743008|2025-12-04 12:19:03|2025-12-04 12:19:03|2025-12-04|\n",
      "|31                |10048224  |2717272    |2025-12-04 07:50:24.574|1          |2025-12-04 07:50:24.48 |CONV.LINE.Status.Product.Recipe.Index               |2.0        |1764834619773|2025-12-04 07:50:19|2025-12-04 07:50:19|2025-12-04|\n",
      "|41                |10052103  |2815887    |2025-12-04 12:19:06.295|2          |2025-12-04 12:19:06.015|CONV.LINE.Status.Product.Recipe.Index               |4.0        |1764850743007|2025-12-04 12:19:03|2025-12-04 12:19:03|2025-12-04|\n",
      "+------------------+----------+-----------+-----------------------+-----------+-----------------------+----------------------------------------------------+-----------+-------------+-------------------+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trasformiamo: { \"Padre\": [\"Figlio1\", \"Figlio2\"] }\n",
    "# In: [ (\"Figlio1\", \"Padre\"), (\"Figlio2\", \"Padre\") ]\n",
    "flat_mapping_data = []\n",
    "\n",
    "for normalized_name, variations_list in mapping_dict.items():\n",
    "    for raw_variant in variations_list:\n",
    "        # Creiamo una riga per ogni variante che punta al nome normalizzato\n",
    "        flat_mapping_data.append((raw_variant, normalized_name))\n",
    "\n",
    "# Definiamo lo schema\n",
    "schema_mapping = StructType([\n",
    "    StructField(\"raw_name_map\", StringType(), True),       # Questo deve matchare il dataset (le varianti)\n",
    "    StructField(\"normalized_name_map\", StringType(), True) # Questo √® il nome finale pulito (la chiave del json)\n",
    "])\n",
    "\n",
    "# Creiamo il DataFrame di mapping corretto\n",
    "df_mapping = spark.createDataFrame(flat_mapping_data, schema=schema_mapping)\n",
    "\n",
    "print(\"Tabella di Mapping Corretta (Esempio):\")\n",
    "df_mapping.show(5, truncate=False)\n",
    "\n",
    "# Se nel dataset (df.name) trovi una variante (df_mapping.raw_name_map),\n",
    "# prendi il suo normalized_name_map.\n",
    "df_normalized = df.join(\n",
    "    df_mapping,\n",
    "    df.name == df_mapping.raw_name_map,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Se la join ha successo, prendi il nome normalizzato, altrimenti tieni quello originale\n",
    "df_final = df_normalized.withColumn(\n",
    "    \"name_clean\", \n",
    "    coalesce(col(\"normalized_name_map\"), col(\"name\"))\n",
    ").drop(\"raw_name_map\", \"normalized_name_map\") # Rimuoviamo le colonne del mapping\n",
    "\n",
    "# Sostituiamo la colonna name vecchia con quella pulita\n",
    "df_final = df_final.withColumn(\"name\", col(\"name_clean\")).drop(\"name_clean\")\n",
    "\n",
    "print(\"Dataset Normalizzato Correttamente:\")\n",
    "df_final.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0425785d-03e9-44ed-81d4-3a360e891384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Analisi Metriche:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:==================================>                      (6 + 4) / 10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------+-----+-----------+------------+--------------+---------------------+\n",
      "|name                                                      |count|min_val    |max_val     |avg_val       |trend_desc           |\n",
      "+----------------------------------------------------------+-----+-----------+------------+--------------+---------------------+\n",
      "|CONV.LS1.Status.Product.Log.CuttingLenght                 |25631|91.8       |217.3       |135.7         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.LINE.Statistics.Production.Log.ProducedNotReset      |25631|8460934.0  |1.4894469E7 |1.161117172E7 |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.LS1.Status.Product.Log.Diameter                      |25631|115.0      |200.0       |144.29        |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.LS1.Statistics.Monitoring.Blade.RemainingPercentage  |25631|37.0       |83.0        |58.42         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.REW.Status.Product.Core.Diameter                     |25631|46.5       |50.0        |48.84         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.LS1.Status.Monitoring.Blade.Diameter                 |25631|37.0       |83.0        |58.42         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.LS1.Status.Product.Log.Lenght                        |25631|2630.0     |3330.0      |2884.57       |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.LINE.Status.Product.Recipe.Index                     |25631|2.0        |21.0        |9.2           |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.REW.Status.Product.Log.PerforationLenght             |25631|85.5       |258.0       |157.69        |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.UNW1.Status.Material.Paper.ReelDiameter              |25631|0.0        |3908.0      |1220.67       |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.LINE.Statistics.Production.Log.RejectedNotReset      |25631|0.0        |358495.0    |170096.18     |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.LS1.Statistics.Production.Rolls.ProducedNotReset     |25631|2.4368851E7|4.15959531E8|1.9759959496E8|Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.REW.Status.Product.Log.Diameter                      |25631|115.5      |196.0       |144.43        |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.ACC1.Statistics.Production.Log.PercentageLevel       |25631|0.0        |100.0       |24.99         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.REW.Status.Product.Log.SheetsNumber                  |25631|160.0      |501.0       |308.97        |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.UNW1.Statistics.Material.Paper.ReelPercentageDiameter|25631|-1.0       |100.0       |52.72         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.BU1.Status.Product.Bag.NumberPackBundleWidth         |17162|3.0        |4.0         |3.5           |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.WR1.Status.Product.Pack.NumberRollWrapperWidth       |17162|1.0        |2.0         |1.5           |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.WR1.Status.Product.Pack.NumberRollWrapperDepth       |17162|2.0        |4.0         |2.99          |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.WR1.Status.Product.Recipe.Index                      |17162|19.0       |35.0        |27.05         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.BU1.Status.Product.Bag.NumberPackBundleDepth         |17162|1.0        |2.0         |1.5           |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.WR1.Status.Product.Pack.RollIntoProduct              |17162|2.0        |16.0        |8.96          |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.WR1.Status.Product.Pack.Type                         |17162|0.0        |1.0         |0.5           |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.WR1.Status.Product.Pack.NumberRollWrapperHeight      |17162|1.0        |2.0         |1.5           |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.BU1.Status.Product.Recipe.Index                      |17162|36.0       |37.0        |36.5          |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.BU1.Status.Product.Bag.NumberPackBundleHeight        |17162|1.0        |1.0         |1.0           |Costante (=)         |\n",
      "|PACK.WR1.Status.Product.Pack.RollOrientation              |17162|0.0        |0.0         |0.0           |Costante (=)         |\n",
      "|PACK.BU1.Status.Product.Bag.RollIntoProduct               |17162|4.0        |6.0         |4.99          |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.UNW3.Statistics.Material.Paper.ReelPercentageDiameter|16999|-1.0       |68.0        |38.41         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.UNW3.Status.Material.Paper.ReelDiameter              |16999|184.0      |1842.0      |1475.73       |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.BU1.Statistics.Production.Bag.ProducedNotReset       |8632 |1.4341055E7|1.4349757E7 |1.434520678E7 |Crescente ‚ÜóÔ∏è         |\n",
      "|PACK.WR1.Statistics.Production.Pack.ProducedNotReset      |8632 |5.2682873E7|5.2717811E7 |5.269956779E7 |Crescente ‚ÜóÔ∏è         |\n",
      "|PACK.WR1.Status.State.ChangeProductOngoing                |8632 |0.0        |0.0         |0.0           |Costante (=)         |\n",
      "|PACK.BU1.Status.State.ChangeProductOngoing                |8632 |0.0        |0.0         |0.0           |Costante (=)         |\n",
      "|PACK.BU1.Status.State.Machine.FirstAlarmCode              |8530 |0.0        |405.0       |6.54          |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.WR1.Status.State.Machine.FirstAlarmCode              |8530 |0.0        |486.0       |158.54        |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.WR1.Status.Monitoring.Machine.Speed                  |8530 |0.0        |54.0        |24.33         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|PACK.BU1.Status.State.Machine.Speed                       |8530 |0.0        |11.0        |8.91          |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.UNW2.Status.Material.Paper.ReelDiameter              |8529 |570.0      |2108.0      |1754.75       |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.UNW4.Status.Material.Paper.ReelDiameter              |8529 |0.0        |1946.0      |1073.25       |Crescente ‚ÜóÔ∏è         |\n",
      "|CONV.UNW2.Statistics.Material.Paper.ReelPercentageDiameter|8529 |0.0        |69.0        |49.92         |Fluttuante/Stabile ‚û°Ô∏è|\n",
      "|CONV.UNW4.Statistics.Material.Paper.ReelPercentageDiameter|8529 |-2.0       |60.0        |21.39         |Crescente ‚ÜóÔ∏è         |\n",
      "+----------------------------------------------------------+-----+-----------+------------+--------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "\n",
    "# Raggruppiamo per 'name' (che ora √® pulito)\n",
    "df_analysis = df_final.groupBy(\"name\").agg(\n",
    "    F.count(\"value\").alias(\"count\"),            # Quanti dati abbiamo?\n",
    "    \n",
    "    # Statistiche di Base\n",
    "    F.round(F.min(\"value\"), 2).alias(\"min_val\"),\n",
    "    F.round(F.max(\"value\"), 2).alias(\"max_val\"),\n",
    "    F.round(F.avg(\"value\"), 2).alias(\"avg_val\"),\n",
    "    F.round(F.stddev(\"value\"), 2).alias(\"std_dev\"),\n",
    "    \n",
    "    # Analisi Temporale (Inizio e Fine rilevazione)\n",
    "    F.min(\"timestamp_true\").alias(\"start_time\"),\n",
    "    F.max(\"timestamp_true\").alias(\"end_time\"),\n",
    "    \n",
    "    # CALCOLO TREND (Correlation)\n",
    "    # Calcola se 'value' sale o scende al passare del 'timestamp'.\n",
    "    # Restituisce un numero tra -1 (Discesa) e +1 (Salita).\n",
    "    F.round(F.corr(\"timestamp\", \"value\"), 3).alias(\"trend_corr\")\n",
    ")\n",
    "\n",
    "df_report = df_analysis.withColumn(\"trend_desc\",\n",
    "    F.when(F.col(\"count\") < 2, \"Dati Insufficienti\")      # Se c'√® solo 1 punto, non c'√® trend\n",
    "    .when(F.col(\"std_dev\") == 0, \"Costante (=)\")          # Se non cambia mai\n",
    "    .when(F.col(\"trend_corr\") > 0.5, \"Crescente ‚ÜóÔ∏è\")      # Forte salita\n",
    "    .when(F.col(\"trend_corr\") < -0.5, \"Decrescente ‚ÜòÔ∏è\")   # Forte discesa\n",
    "    .otherwise(\"Fluttuante/Stabile ‚û°Ô∏è\")                   # Oscilla o cambia poco\n",
    ").orderBy(F.desc(\"count\"))\n",
    "\n",
    "# 3. VISUALIZZAZIONE REPORT\n",
    "print(\"Report Analisi Metriche:\")\n",
    "df_report.select(\n",
    "    \"name\", \"count\", \"min_val\", \"max_val\", \"avg_val\", \"trend_desc\"\n",
    ").show(1000, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d49cf87-09b3-43e4-8176-30ebf67355a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALISI DEGLI STATI OPERATIVI (CLUSTERING PER SINGOLA METRICA) ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Analisi Metrica: CONV.LS1.Status.Product.Log.CuttingLenght (25631 righe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/12 08:54:56 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìä Stati rilevati: ['91.80', '97.52', '216.51']\n",
      "+----------+-----+-------+\n",
      "|prediction|count|avg_val|\n",
      "+----------+-----+-------+\n",
      "|0         |8470 |91.8   |\n",
      "|2         |8529 |97.52  |\n",
      "|1         |8632 |216.51 |\n",
      "+----------+-----+-------+\n",
      "\n",
      "------------------------------------------------------------\n",
      "üîπ Analisi Metrica: CONV.LINE.Statistics.Production.Log.ProducedNotReset (25631 righe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/socket.py\", line 720, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 4. Applichiamo K-Means (k=3)\u001b[39;00m\n\u001b[32m     37\u001b[39m kmeans = KMeans(k=\u001b[32m3\u001b[39m, seed=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m model = \u001b[43mkmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# 5. Estraiamo i CENTRI (Valori tipici)\u001b[39;00m\n\u001b[32m     41\u001b[39m centers = model.clusterCenters()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/ml/base.py:205\u001b[39m, in \u001b[36mEstimator.fit\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(params)._fit(dataset)\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[32m    210\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/ml/wrapper.py:381\u001b[39m, in \u001b[36mJavaEstimator._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) -> JM:\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     java_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m     model = \u001b[38;5;28mself\u001b[39m._create_model(java_model)\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._copyValues(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/ml/wrapper.py:378\u001b[39m, in \u001b[36mJavaEstimator._fit_java\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28mself\u001b[39m._transfer_params_to_java()\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_java_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/py4j/java_gateway.py:1321\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1314\u001b[39m args_command, temp_args = \u001b[38;5;28mself\u001b[39m._build_args(*args)\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m-> \u001b[39m\u001b[32m1321\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1322\u001b[39m return_value = get_return_value(\n\u001b[32m   1323\u001b[39m     answer, \u001b[38;5;28mself\u001b[39m.gateway_client, \u001b[38;5;28mself\u001b[39m.target_id, \u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/py4j/java_gateway.py:1038\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1036\u001b[39m connection = \u001b[38;5;28mself\u001b[39m._get_connection()\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[32m   1040\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m._create_connection_guard(connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/py4j/clientserver.py:511\u001b[39m, in \u001b[36mClientServerConnection.send_command\u001b[39m\u001b[34m(self, command)\u001b[39m\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    510\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m         answer = smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:-\u001b[32m1\u001b[39m])\n\u001b[32m    512\u001b[39m         logger.debug(\u001b[33m\"\u001b[39m\u001b[33mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m\"\u001b[39m.format(answer))\n\u001b[32m    513\u001b[39m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[32m    514\u001b[39m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"=== ANALISI DEGLI STATI OPERATIVI (CLUSTERING PER SINGOLA METRICA) ===\\n\")\n",
    "\n",
    "# 1. Otteniamo la lista di tutte le metriche uniche\n",
    "unique_metrics = [row['name'] for row in df_final.select(\"name\").distinct().collect()]\n",
    "\n",
    "for metric_name in unique_metrics:\n",
    "    \n",
    "    # 2. Filtro iniziale per nome\n",
    "    df_single_metric = df_final.filter(F.col(\"name\") == metric_name)\n",
    "    \n",
    "    # Rimuoviamo NULL E ANCHE NaN\n",
    "    # Convertiamo prima in Double per essere sicuri che isnan funzioni\n",
    "    df_clean = df_single_metric.withColumn(\"value\", F.col(\"value\").cast(DoubleType())) \\\n",
    "        .filter(\n",
    "            F.col(\"value\").isNotNull() & \n",
    "            (~F.isnan(F.col(\"value\")))\n",
    "        )\n",
    "    \n",
    "    # Cache per velocizzare dato che usiamo questo df pi√π volte (count e fit)\n",
    "    df_clean.cache()\n",
    "    \n",
    "    # Controllo: abbiamo abbastanza dati PULITI?\n",
    "    data_count = df_clean.count()\n",
    "    if data_count < 3:\n",
    "        df_clean.unpersist() # Liberiamo memoria\n",
    "        continue\n",
    "\n",
    "    print(f\"üîπ Analisi Metrica: {metric_name} ({data_count} righe)\")\n",
    "\n",
    "    try:\n",
    "        # 3. Prepariamo il dato 'value'\n",
    "        assembler = VectorAssembler(inputCols=[\"value\"], outputCol=\"features\")\n",
    "        df_vec = assembler.transform(df_clean)\n",
    "\n",
    "        # 4. Applichiamo K-Means (k=3)\n",
    "        kmeans = KMeans(k=3, seed=1)\n",
    "        model = kmeans.fit(df_vec)\n",
    "        \n",
    "        # 5. Estraiamo i CENTRI (Valori tipici)\n",
    "        centers = model.clusterCenters()\n",
    "        # Prendi il valore scalare dal vettore del centroide\n",
    "        centers_values = sorted([float(c[0]) for c in centers])\n",
    "        centers_str = [f\"{v:.2f}\" for v in centers_values]\n",
    "        \n",
    "        print(f\"   üìä Stati rilevati: {centers_str}\")\n",
    "        \n",
    "        # 6. Distribuzione\n",
    "        predictions = model.transform(df_vec)\n",
    "        summary = predictions.groupBy(\"prediction\").agg(\n",
    "            F.count(\"value\").alias(\"count\"),\n",
    "            F.round(F.avg(\"value\"), 2).alias(\"avg_val\")\n",
    "        ).orderBy(\"avg_val\")\n",
    "        \n",
    "        summary.show(truncate=False)\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore processando {metric_name}: {e}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Pulizia finale della memoria per questo ciclo\n",
    "    df_clean.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892a7c3-ac72-40b4-83f5-dfd3b848faad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
